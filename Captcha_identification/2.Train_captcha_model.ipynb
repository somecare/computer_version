{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow.contrib.slim as slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据路径\n",
    "dataset_dir = './captcha/'\n",
    "\n",
    "#测试数据集占比\n",
    "num_test = 0.2\n",
    "#批次大小\n",
    "batch_size = 32\n",
    "#周期大小\n",
    "epochs = 100\n",
    "#分类数\n",
    "num_classes = 10\n",
    "#学习率\n",
    "lr = tf.Variable(0.001,dtype=tf.float32)\n",
    "#是否为训练状态\n",
    "is_training = tf.placeholder(tf.bool)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#获取所有验证码图片路径和标签\n",
    "def get_filename_and_classes(dataset_dir):\n",
    "    photo_filenames = []\n",
    "    labels = []\n",
    "    for filename in os.listdir(dataset_dir):\n",
    "        #获取文件路径\n",
    "        path = os.path.join(dataset_dir,filename)\n",
    "        photo_filenames.append(path)\n",
    "        label = filename[0:4]\n",
    "        num_labels = []\n",
    "        for i in range(4):\n",
    "            num_labels.append(int(label[i]))\n",
    "        labels.append(num_labels)\n",
    "    return photo_filenames,labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#获取图片路径和标签\n",
    "photo_filenames,labels = get_filename_and_classes(dataset_dir)\n",
    "photo_filenames = np.array(photo_filenames)\n",
    "labels = np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#打乱数据\n",
    "np.random.seed(10)\n",
    "shuffle_indices = np.random.permutation(np.arange(len(photo_filenames)))\n",
    "photo_filenames_shuffled = photo_filenames[shuffle_indices]\n",
    "labels_shuffled = labels[shuffle_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#切分数据集\n",
    "test_sample_index = -1 * int(num_test * float(len(photo_filenames)))\n",
    "x_train,x_test = photo_filenames_shuffled[:test_sample_index],photo_filenames_shuffled[test_sample_index:]\n",
    "y_train,y_test = labels_shuffled[:test_sample_index],labels_shuffled[test_sample_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#图像处理函数\n",
    "def parse_function(filenames,labels = None):\n",
    "    #读取图片并解码\n",
    "    image = tf.read_file(filenames)\n",
    "    image = tf.image.decode_jpeg(image,channels=3)\n",
    "    #resize\n",
    "    image = tf.image.resize_images(image,[224,224])\n",
    "    \n",
    "    image = tf.cast(image,tf.float32) / 255.0\n",
    "    image = tf.subtract(image,0.5)\n",
    "    image = tf.multiply(image,2.0)\n",
    "    \n",
    "    return image,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义placeholder\n",
    "features_placeholder = tf.placeholder(photo_filenames_shuffled.dtype,[None])\n",
    "labels_placeholder = tf.placeholder(labels_shuffled.dtype,[None,4])\n",
    "\n",
    "#创建dataset对象()\n",
    "dataset = tf.data.Dataset.from_tensor_slices((features_placeholder,labels_placeholder))\n",
    "#预处理图片\n",
    "dataset = dataset.map(parse_function)\n",
    "#训练周期\n",
    "dataset = dataset.repeat(1)\n",
    "#批次大小\n",
    "dataset = dataset.batch(batch_size)\n",
    "\n",
    "#初始化迭代器\n",
    "iterator = dataset.make_initializable_iterator()\n",
    "\n",
    "#获得一个批次数据和标签\n",
    "data_batch,label_batch = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alexnet(inputs,is_training=True):\n",
    "    with slim.arg_scope([slim.conv2d,slim.fully_connected],\n",
    "                       activation_fn = tf.nn.relu,\n",
    "                       weights_initializer = tf.glorot_uniform_initializer(),\n",
    "                       biases_initializer = tf.constant_initializer(0)):\n",
    "        \n",
    "        net = slim.conv2d(inputs,64,[11,11],4)\n",
    "        net = slim.max_pool2d(net,[3,3])\n",
    "        net = slim.conv2d(net,192,[5,5])\n",
    "        net = slim.max_pool2d(net,[3,3])\n",
    "        net = slim.conv2d(net,384,[3,3])\n",
    "        net = slim.conv2d(net,384,[3,3])\n",
    "        net = slim.conv2d(net,256,[3,3])\n",
    "        net = slim.max_pool2d(net,[3,3])\n",
    "        \n",
    "        #数据扁平化\n",
    "        net = slim.flatten(net)\n",
    "        net = slim.fully_connected(net,1024)\n",
    "        net = slim.dropout(net,is_training=is_training)\n",
    "        \n",
    "        #分为四项输出\n",
    "        net0 = slim.fully_connected(net,num_classes,activation_fn=tf.nn.softmax)\n",
    "        net1 = slim.fully_connected(net,num_classes,activation_fn=tf.nn.softmax)\n",
    "        net2 = slim.fully_connected(net,num_classes,activation_fn=tf.nn.softmax)\n",
    "        net3 = slim.fully_connected(net,num_classes,activation_fn=tf.nn.softmax)\n",
    "        \n",
    "    return net0,net1,net2,net3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第0个批次训练完成！\n",
      "0:loss=2.303 acc0=0.100 acc1=0.095 acc2=0.095 acc3=0.089 total_acc=0.000\n",
      "第1个批次训练完成！\n",
      "1:loss=2.258 acc0=0.179 acc1=0.159 acc2=0.191 acc3=0.218 total_acc=0.000\n",
      "第2个批次训练完成！\n",
      "2:loss=2.199 acc0=0.270 acc1=0.213 acc2=0.220 acc3=0.295 total_acc=0.004\n",
      "第3个批次训练完成！\n",
      "3:loss=2.163 acc0=0.337 acc1=0.247 acc2=0.264 acc3=0.286 total_acc=0.005\n",
      "第4个批次训练完成！\n",
      "4:loss=2.129 acc0=0.374 acc1=0.313 acc2=0.302 acc3=0.317 total_acc=0.014\n",
      "第5个批次训练完成！\n",
      "5:loss=2.054 acc0=0.455 acc1=0.346 acc2=0.365 acc3=0.430 total_acc=0.018\n",
      "第6个批次训练完成！\n",
      "6:loss=2.007 acc0=0.531 acc1=0.406 acc2=0.407 acc3=0.462 total_acc=0.035\n",
      "第7个批次训练完成！\n",
      "7:loss=1.953 acc0=0.599 acc1=0.460 acc2=0.463 acc3=0.494 total_acc=0.058\n",
      "第8个批次训练完成！\n",
      "8:loss=1.914 acc0=0.636 acc1=0.513 acc2=0.501 acc3=0.541 total_acc=0.093\n",
      "第9个批次训练完成！\n",
      "9:loss=1.896 acc0=0.647 acc1=0.545 acc2=0.488 acc3=0.568 total_acc=0.108\n",
      "第10个批次训练完成！\n",
      "10:loss=1.855 acc0=0.686 acc1=0.544 acc2=0.538 acc3=0.651 total_acc=0.140\n",
      "第11个批次训练完成！\n",
      "11:loss=1.850 acc0=0.687 acc1=0.581 acc2=0.560 acc3=0.613 total_acc=0.149\n",
      "第12个批次训练完成！\n",
      "12:loss=1.807 acc0=0.721 acc1=0.590 acc2=0.611 acc3=0.682 total_acc=0.185\n",
      "第13个批次训练完成！\n",
      "13:loss=1.775 acc0=0.764 acc1=0.627 acc2=0.663 acc3=0.688 total_acc=0.243\n",
      "第14个批次训练完成！\n",
      "14:loss=1.756 acc0=0.818 acc1=0.618 acc2=0.692 acc3=0.686 total_acc=0.274\n",
      "第15个批次训练完成！\n",
      "15:loss=1.731 acc0=0.868 acc1=0.654 acc2=0.687 acc3=0.715 total_acc=0.300\n",
      "第16个批次训练完成！\n",
      "16:loss=1.696 acc0=0.859 acc1=0.711 acc2=0.727 acc3=0.766 total_acc=0.372\n",
      "第17个批次训练完成！\n",
      "17:loss=1.683 acc0=0.871 acc1=0.738 acc2=0.705 acc3=0.801 total_acc=0.392\n",
      "第18个批次训练完成！\n",
      "18:loss=1.656 acc0=0.892 acc1=0.752 acc2=0.762 acc3=0.811 total_acc=0.449\n",
      "第19个批次训练完成！\n",
      "19:loss=1.648 acc0=0.918 acc1=0.762 acc2=0.769 acc3=0.812 total_acc=0.487\n",
      "第20个批次训练完成！\n",
      "20:loss=1.655 acc0=0.909 acc1=0.758 acc2=0.758 acc3=0.793 total_acc=0.449\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-170577fe6fe5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m                 \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mis_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m                 \u001b[1;31m#所有数据训练完成后跳出循环\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1135\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1316\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1320\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1307\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m           run_metadata)\n\u001b[0m\u001b[0;32m   1410\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    #传入数据得到结果\n",
    "    logits0,logits1,logits2,logits3 = alexnet(data_batch,is_training)\n",
    "    #定义loss\n",
    "    #sparse_softmax_cross_entropyy：标签为整数\n",
    "    # softmax_cross_entripy:标签为one-hot独热编码\n",
    "    loss0 = tf.losses.sparse_softmax_cross_entropy(label_batch[:,0],logits0)\n",
    "    loss1 = tf.losses.sparse_softmax_cross_entropy(label_batch[:,1],logits1)\n",
    "    loss2 = tf.losses.sparse_softmax_cross_entropy(label_batch[:,2],logits2)\n",
    "    loss3 = tf.losses.sparse_softmax_cross_entropy(label_batch[:,3],logits3)\n",
    "    #计算总的loss\n",
    "    total_loss = (loss0+loss1+loss2+loss3)/4.0\n",
    "    #优化loss\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=lr).minimize(total_loss)\n",
    "    \n",
    "    #计算准确率\n",
    "    correct0 = tf.nn.in_top_k(logits0,label_batch[:,0],1)\n",
    "    accuracy0 = tf.reduce_mean(tf.cast(correct0,tf.float32))\n",
    "    correct1 = tf.nn.in_top_k(logits1,label_batch[:,1],1)\n",
    "    accuracy1 = tf.reduce_mean(tf.cast(correct1,tf.float32))\n",
    "    correct2 = tf.nn.in_top_k(logits2,label_batch[:,2],1)\n",
    "    accuracy2 = tf.reduce_mean(tf.cast(correct2,tf.float32))\n",
    "    correct3 = tf.nn.in_top_k(logits3,label_batch[:,3],1)\n",
    "    accuracy3 = tf.reduce_mean(tf.cast(correct3,tf.float32))\n",
    "    #总的准确率\n",
    "    total_correct = tf.cast(correct0,tf.float32)*tf.cast(correct1,tf.float32)*tf.cast(correct2,tf.float32)*tf.cast(correct3,tf.float32)\n",
    "    total_accuracy = tf.reduce_mean(tf.cast(total_correct,tf.float32))\n",
    "    \n",
    "    #所有变量初始化\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    #定义saver保存模型\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    #训练一个epochs周期\n",
    "    for i in range(epochs):\n",
    "        if i%30 == 0:\n",
    "            sess.run(tf.assign(lr,lr/3))\n",
    "        #训练集传入迭代器\n",
    "        sess.run(iterator.initializer,feed_dict={features_placeholder:x_train,\n",
    "                                                labels_placeholder:y_train})\n",
    "        \n",
    "        #训练模型\n",
    "        while True:\n",
    "            try:\n",
    "                sess.run(optimizer,feed_dict={is_training:True})\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                #所有数据训练完成后跳出循环\n",
    "                print('第%d个批次训练完成！'%i)\n",
    "                break\n",
    "        #测试集放入迭代器中\n",
    "        sess.run(iterator.initializer,feed_dict={features_placeholder:x_test,\n",
    "                                                labels_placeholder:y_test})\n",
    "        #测试结果\n",
    "        while True:\n",
    "            try:\n",
    "                #获得准确率和loss\n",
    "                acc0,acc1,acc2,acc3,total_acc,result_loss = \\\n",
    "                    sess.run([accuracy0,accuracy1,accuracy2,accuracy3,total_accuracy,total_loss],feed_dict={is_training:False})\n",
    "\n",
    "                #loss值统计\n",
    "                tf.add_to_collection('sum_losses',result_loss)\n",
    "                #准确率统计\n",
    "                tf.add_to_collection('accuracy0',acc0)\n",
    "                tf.add_to_collection('accuracy1',acc1)\n",
    "                tf.add_to_collection('accuracy2',acc2)\n",
    "                tf.add_to_collection('accuracy3',acc3)\n",
    "                tf.add_to_collection('total_acc',total_acc)\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                #loss值求平均\n",
    "                avg_loss = sess.run(tf.reduce_mean(tf.get_collection('sum_losses')))\n",
    "                #准确率求平均\n",
    "                avg_acc0 = sess.run(tf.reduce_mean(tf.get_collection('accuracy0')))\n",
    "                avg_acc1 = sess.run(tf.reduce_mean(tf.get_collection('accuracy1')))\n",
    "                avg_acc2 = sess.run(tf.reduce_mean(tf.get_collection('accuracy2')))\n",
    "                avg_acc3 = sess.run(tf.reduce_mean(tf.get_collection('accuracy3')))\n",
    "                avg_total_acc = sess.run(tf.reduce_mean(tf.get_collection('total_acc')))\n",
    "                print('%d:loss=%.3f acc0=%.3f acc1=%.3f acc2=%.3f acc3=%.3f total_acc=%.3f'%\n",
    "                     (i,avg_loss,avg_acc0,avg_acc1,avg_acc2,avg_acc3,avg_total_acc))\n",
    "                \n",
    "                #清空loss统计\n",
    "                temp = tf.get_collection_ref('sum_losses')\n",
    "                del temp[:]\n",
    "                \n",
    "                #清空准确率统计\n",
    "                temp = tf.get_collection_ref('accuracy0')\n",
    "                del temp[:]\n",
    "                temp = tf.get_collection_ref('accuracy1')\n",
    "                del temp[:]\n",
    "                temp = tf.get_collection_ref('accuracy2')\n",
    "                del temp[:]\n",
    "                temp = tf.get_collection_ref('accuracy3')\n",
    "                del temp[:]\n",
    "                temp = tf.get_collection_ref('total_acc')\n",
    "                del temp[:]\n",
    "                break\n",
    "    #保存模型\n",
    "    saver.save(sess,'models/model.ckpt',global_step=epochs)\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
